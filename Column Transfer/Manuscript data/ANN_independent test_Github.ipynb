{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8739e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    " \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import scale \n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e67cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1790 entries, 0 to 1789\n",
      "Columns: 141 entries, H to fsulfone\n",
      "dtypes: float64(100), int64(41)\n",
      "memory usage: 1.9 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1790 entries, 0 to 1789\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tR (min)  1790 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 14.1 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 143\n",
      "Columns: 141 entries, H to fsulfone\n",
      "dtypes: float64(100), int64(41)\n",
      "memory usage: 110.9 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 143\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tR (min)  100 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 1.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import training datadet\n",
    "inter = pd.ExcelFile('training data_Github.xlsx')\n",
    "inter = pd.read_excel(inter,'Combined')\n",
    "\n",
    "comb = inter.dropna(axis=0)\n",
    "comb = comb[comb[\"tR (min)\"] != \"?\"]\n",
    "col_to_remove=[]\n",
    "#preprocess\n",
    "for col in comb.columns[1:]:\n",
    "    if (comb[col] == 0).all():\n",
    "        comb = comb.drop([col], axis = 1)\n",
    "        col_to_remove.append(col)\n",
    "comb = comb.reset_index(drop=True)\n",
    "X_CAL = comb.drop(['Project','Column','Compound','tR (min)'], axis=1)\n",
    "print(X_CAL.info())\n",
    "y = {'tR (min)': [round(x,4) for x in comb['tR (min)']]}\n",
    "y = pd.DataFrame(comb, columns = ['tR (min)'])\n",
    "print(y.info())\n",
    "#import test data\n",
    "inter1 = pd.ExcelFile('test data_Github.xlsx')\n",
    "inter1 = pd.read_excel(inter1,'Sheet2')\n",
    "\n",
    "test = inter1.dropna(axis=0)\n",
    "test = test[test[\"tR (min)\"] != \"?\"]\n",
    "#preprocess\n",
    "test = test.drop(col_to_remove,axis=1)\n",
    "X_test = test.drop(['Project','Column','Compound','tR (min)'], axis=1)\n",
    "print(X_test.info())\n",
    "y_test = {'tR (min)': [round(x,4) for x in test['tR (min)']]}\n",
    "y_test = pd.DataFrame(test, columns = ['tR (min)'])\n",
    "print(y_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d33085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def HPLC_COLUMN_TRANSFER_independent_test(X_CAL,Y_CAL,X_test,Y_test,Project_IN):\n",
    "    \n",
    "    UNIQUE_LIST = test['Column'].unique()\n",
    "    print(UNIQUE_LIST)\n",
    "    print(test['Project'].unique())\n",
    "    RMSEP_1 = []\n",
    "    RMSEP_2 = []\n",
    "    LABEL = []\n",
    "    Project = Project_IN  # Example project\n",
    "\n",
    "    for i in range(5):\n",
    "        for k in range(i + 1, 5):\n",
    "            ind_cal = (test['Project'] == Project) & (test['Column'] == UNIQUE_LIST[i])\n",
    "            ind_val = (test['Project'] == Project) & (test['Column'] == UNIQUE_LIST[k])\n",
    "\n",
    "            if ind_cal.sum() < 3 or ind_val.sum() < 3:\n",
    "                continue\n",
    "            else: \n",
    "\n",
    "                # ANN\n",
    "                XScaler=StandardScaler()\n",
    "                YScaler=StandardScaler()\n",
    "                temp_x=np.vstack([X_CAL, X_test.loc[ind_cal,:]])\n",
    "                temp_y=np.vstack([y, Y_test.loc[ind_cal,:]])\n",
    "                temp_x_test = X_test.loc[ind_val,:]\n",
    "                temp_y = np.asarray(temp_y).astype('float32')\n",
    "                temp_x = np.asarray(temp_x).astype('float32')\n",
    "                temp_x_test = np.asarray(temp_x_test).astype('float32')\n",
    "    \n",
    "                X_scaled=XScaler.fit_transform(temp_x)\n",
    "                y_scaled=YScaler.fit_transform(temp_y)\n",
    "                X_test_scaled=XScaler.transform(temp_x_test)\n",
    "\n",
    "                # create ANN model\n",
    "                model = Sequential()\n",
    "                # Defining the Input layer and FIRST hidden layer, both are same!\n",
    "                model.add(Dense(units=5, input_dim=141, kernel_initializer='normal', activation='relu'))\n",
    "                # Defining the Second layer of the model\n",
    "                # after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "                model.add(Dense(units=10, kernel_initializer='normal', activation='relu'))\n",
    "                # Defining the Third layer of the model\n",
    "                model.add(Dense(units=10, kernel_initializer='normal', activation='relu'))\n",
    "                # The output neuron is a single fully connected node \n",
    "                # Since we will be predicting a single number\n",
    "                model.add(Dense(1, kernel_initializer='normal'))\n",
    "                # Compiling the model\n",
    "                model.compile(loss='mean_squared_error', optimizer='adam')    \n",
    "                # Fitting the ANN to the Training set\n",
    "                model.fit(X_scaled, y_scaled ,batch_size = 50, epochs = 50, verbose=0)\n",
    "\n",
    "                \n",
    "                # Generating Predictions on testing data\n",
    "                Predictions=model.predict(X_test_scaled)\n",
    "                # Scaling the predicted Price data back to original price scale\n",
    "                Predictions=YScaler.inverse_transform(Predictions)\n",
    "                RMSEP_temp = np.sqrt(mean_squared_error(Y_test.loc[ind_val], Predictions))\n",
    "                tempA=test.loc[ind_cal, 'Compound'].values\n",
    "                tempA = [[item] for item in tempA]\n",
    "                tempB=test.loc[ind_val, 'Compound'].values\n",
    "                tempB = [[item] for item in tempB]\n",
    "                \n",
    "                LABEL.append([\n",
    "                    UNIQUE_LIST[i],\n",
    "                    tempA,\n",
    "                    UNIQUE_LIST[k],\n",
    "                    tempB,\n",
    "                    ind_val.sum(),\n",
    "                    Y_test.loc[ind_val], \n",
    "                    Predictions\n",
    "                ])\n",
    "\n",
    "                RMSEP_2.append(RMSEP_temp)\n",
    "\n",
    "               \n",
    "\n",
    "    OUTPUT = {\n",
    "        'LABEL': LABEL,\n",
    "        'RMSEP_2': RMSEP_2\n",
    "    }\n",
    "    \n",
    "    return OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a80bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zorbax Extend C18' 'Kinetix XB-C18' 'Poroshell EC-C18' 'Cortecs C18+'\n",
      " 'ACE C18']\n",
      "['Project CC' 'Project AA' 'Project BB' 'Project DD']\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "#OUTPUT=HPLC_COLUMN_TRANSFER_independent_test(X_CAL,y,X_test,y_test,'Project AA')\n",
    "#OUTPUT=HPLC_COLUMN_TRANSFER_independent_test(X_CAL,y,X_test,y_test,'Project BB')\n",
    "#OUTPUT=HPLC_COLUMN_TRANSFER_independent_test(X_CAL,y,X_test,y_test,'Project CC')\n",
    "OUTPUT=HPLC_COLUMN_TRANSFER_independent_test(X_CAL,y,X_test,y_test,'Project DD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "344d8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(OUTPUT['LABEL'][0][1])\n",
    "\n",
    "samp=[]\n",
    "columnA=[]\n",
    "columnB=[]\n",
    "CompoundA=np.array\n",
    "CompoundB=np.array\n",
    "Rt_mea=np.array\n",
    "Rt_pre=np.array\n",
    "rmse_ANN=[]\n",
    "\n",
    "for i in range(len(OUTPUT['LABEL'])):\n",
    "    columnA.append(OUTPUT['LABEL'][i][0])\n",
    "    columnB.append(OUTPUT['LABEL'][i][2])\n",
    "    tempA=np.array(OUTPUT['LABEL'][i][1])\n",
    "    CompoundA=np.vstack([CompoundA,tempA])\n",
    "    tempB=np.array(OUTPUT['LABEL'][i][3])\n",
    "    CompoundB=np.vstack([CompoundB,tempB])\n",
    "    samp.append(OUTPUT['LABEL'][i][4])\n",
    "    temp_mea=np.array(OUTPUT['LABEL'][i][5])\n",
    "    Rt_mea=np.vstack([Rt_mea,temp_mea])\n",
    "    temp_pre=np.array(OUTPUT['LABEL'][i][6])\n",
    "    Rt_pre=np.vstack([Rt_pre,temp_pre])\n",
    "    rmse_ANN.append(OUTPUT['RMSEP_2'][i])\n",
    "\n",
    "\n",
    "tempA=np.array(CompoundA)\n",
    "CompoundA=tempA.reshape(-1,1)\n",
    "\n",
    "tempB=np.array(CompoundB)\n",
    "CompoundB=tempB.reshape(-1,1)\n",
    "\n",
    "columnA=pd.DataFrame(columnA,columns=['columnA'])\n",
    "columnB=pd.DataFrame(columnB,columns=['columnB'])\n",
    "CompoundA=pd.DataFrame(CompoundA[1:,:],columns=['CompoundA'])\n",
    "CompoundB=pd.DataFrame(CompoundB[1:,:],columns=['CompoundB'])\n",
    "samp=pd.DataFrame(samp,columns=['# of samples'])\n",
    "Rt_mea=pd.DataFrame(Rt_mea[1:,:],columns=['measured Rt'])\n",
    "Rt_pre=pd.DataFrame(Rt_pre[1:,:],columns=['predicted Rt'])\n",
    "rmse_ANN=pd.DataFrame(rmse_ANN,columns=['rmse_ANN'])\n",
    "\n",
    "results = pd.concat([columnA, columnB, CompoundA, CompoundB, samp, Rt_mea, Rt_pre, rmse_ANN],axis=1)\n",
    "\n",
    "#results.to_csv('COLUMN_TRANSFER_Project AA.csv')\n",
    "#results.to_csv('COLUMN_TRANSFER_Project BB.csv')\n",
    "#results.to_csv('COLUMN_TRANSFER_Project CC.csv')\n",
    "results.to_csv('COLUMN_TRANSFER_Project DD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07decf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
